{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Clustering and Centrality Measures\n",
    "\n",
    "In this networks, we are once again going to work with the Jazz musician network the we have already used in last week's exercise. Throughout this exercise, we will denote this graph with $G$, and its adjacency matrix with $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import List, Optional, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('jazz.txt', nodetype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ Determine the average local clustering coefficient of all nodes in the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Print all nodes in the network which have a local clustering of 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ Create a plot of the graph in which all nodes are colored proportional to their local clustering coefficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Katz Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ Apply networkX to compute the Katz centrality of all nodes in the graph (using default parameters $\\alpha=0.1$ and $\\beta = 1$). Note that networkX offers two functions for this, and that by default the centrality vectors are normalized so that its $L_2$-Norm equals 1.\n",
    "Why does one method fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Apply the `linalg` module from numpy or scipy to compute the largest eigenvalue $\\lambda_{max}$ of the adjacency matrix of $G$, and its inverse value, which yields the maximum value of alpha that can be used to determine Katz centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ For some $\\alpha < \\lambda_{max}^{-1}$, compute the 10 most central nodes in the network, and plot the network using a spring layout with the most central nodes having a distinct color. Feel free to try out other values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Eigenvalue Centrality and PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ Apply networkX to compute the Eigenvector centrality of $G$. What are the most central nodes according to this measure? Do they coincide with the most central nodes with respect to Katz centrality? Again, plot the network with the 10 most central nodes in a distinct color. Note that you can fix the orientation of the plotted network by setting a seed in the layout that you pass to the `pos` argument in `nx.draw()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ In a normalized version of the eigenvector centrality, each row of $A$ is normalized by the (out-)degree of the corresponding node, i.e., we obtain the normalized matrix $P$ with\n",
    "$$P_{ij} = 1/k_i^{out} \\cdot A_{ij}\\ .$$\n",
    "Intuitively, this matrix models the probability that a random walker at node $i$ will move to node $j$ in the next step of his walk. Assuming a (strongly) connected graph, the eigenvector centrality of node $i$ then models the probability that after $n\\rightarrow\\infty$ steps, the random walker is at node $i$.  \n",
    "The eigenvector centrality of the matrix can be computed via the equation\n",
    "$P^Tx$ = $\\lambda_1 x$, i.e., the left eigenvector of $P$ corresponding to the biggest eigenvalue.\n",
    "Write a function that computes the normalized eigenvector centrality, using the function signature in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_eigencentrality(G: nx.Graph) -> Dict[int, float]):\n",
    "    \"\"\"\n",
    "    :param G: networkX graph, might be directed\n",
    "    :\n",
    "    :return: dict with node ID as keys and pagerank score as value\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ Apply the eigenvalue to $G$. How does the result relate to your result in __a)__? Again, determine the nodes with the ten highest centralities, and plot the graph as in 2c) and 3a)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d)__ Compute the normalized eigenvector centrality of the directed path graph $H$ that is initialized in the cell below. Note that since the last node does not have an outgoing link, we give it a self-loop. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__e)__ To account for such \"spider traps\" in random walks, the __PageRank__ algorithm introduces the concept of random restarts. Assuming that during a random walk we are currently at node $i$, we either follow one of its outgoing links, or we randomly teleport to any other node in the network. To model this setting, a _damping factor_ $s\\in (0,1)$ is introduced, which models the probability that the random walker decides to follow an outgoing link in the network instead of randomly teleporting, i.e., for $s=0.9$ the random walker will follow an outgoing edge with 90\\% probability, and randomly teleport with a probability of 10\\%.\n",
    "Using these variables, the PageRank centrality $x^{PR}_i$ of node $i$ is defined as\n",
    "$$\n",
    "x^{PR}_i = s\\sum_{j=1}^N P_{ji}x^{PR}_j + (1-s)/N \\ .\n",
    "$$\n",
    "Note that while this equation can be directly solved algebraically, the more efficient way to compute the PageRank vector $X^{PR}$ via the following iteration (using theory on Markov chains, one can prove that this iteration always converges):\n",
    "$$\n",
    " X^{PR} \\gets sP^TX^{PR} + (1-s)/Ne\n",
    "$$\n",
    "where $e$ is the $n$-dimensional vector in which all elements equal $1$, and where $X^{PR}$ can be initialized randomly as long as its elements sum to 1.\n",
    "\n",
    "Write a function that computes the PageRank centrality of a given a graph, using the signature in the cell below. Initialize your centrality vector by setting all its elements to $1/N$.\n",
    "\n",
    "__Note:__ The PageRank algorithm is named after Larry Page, the co-founder of Google, who has initially invented this algorithm to rank webpages which fit a web search query. More details on this algorithm and its real-life adaptations are taught in our lecture on _Web Mining_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G: nx.Graph, s: Optional[float]=0.85, eps: Optional[float]=1e-06,max_iter: Optional[int]=1000) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    :param G: networkX graph, might be directed\n",
    "    :param s: damping factor\n",
    "    :param eps: tolerance for convergence, iteration should be stopped when ||X-X_old||_2 < eps\n",
    "    :param max_iter: maximum number of iterations after which to break\n",
    "    :\n",
    "    :return: dict with node ID as keys and pagerank score as value\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__f)__ Apply your implementation to compute the PageRank of the nodes in $G$ and in the path graph $H$. One final time, determine the nodes with the ten highest centralities in $G$, and plot the graph as in 2c) and 3a)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
