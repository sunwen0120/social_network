{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social Networks SS21\n",
    "\n",
    "# Home Assignment 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Instructions\n",
    "\n",
    "Submit your solution via Moodle until 23.59pm on Monday, June 28th.\n",
    "Late submissions are accepted for 12 hours following the deadline, with 1/4 of the total possible points deducted from the score.\n",
    "\n",
    "Submit your solutions in teams of 2-4 members.\n",
    "Please denote all members of the team with their student ID and full name in the notebook.\n",
    "Please submit only one notebook per team.\n",
    "Only submit a notebook, do not submit the datasets you used or image files that you have created - these have to be created from your notebook.\n",
    "Also, do NOT compress/zip your submission!\n",
    "\n",
    "Cite ALL your sources for coding this home assignment.\n",
    "In case of plagiarism (copying solutions from other teams or from the internet), ALL team members will be expelled from the course without warning.\n",
    "\n",
    "\n",
    "### Evaluation and Grading\n",
    "\n",
    "Evaluation of your submission is done semi-automatically.\n",
    "Think of it as this notebook being executed once.\n",
    "Afterwards, some test functions are appended to this file and executed respectively.\n",
    "\n",
    "Therefore:\n",
    "* Submit valid _Python3_ code only!\n",
    "* Make sure to restrict yourself to using packages that are automatically installed along with anaconda, plus some additional packages that have been introduced in context of this class. An overview of packages that may be used in this assignment can be found in the file 'environment.yaml'.\n",
    "* Ensure your definitions (functions, classes, methods, variables) follow the specification if\n",
    "  given. The concrete signature and header of a function is usually specified in the task description and via code skeletons.\n",
    "* Again, make sure that all your function as well as variable names match with what we have specified! The automated grading will only match these exact names, and everything that can not be matched will not be graded.\n",
    "* Whenever there is a written task, e.g. task 1b), enter your answer in the specified markdown cell. Do NOT remove or edit the label (e.g. '__A1b):__' ) from the markdown cell, as this will have to be parsed by the grading system and matched to your answer. \n",
    "* Ensure the notebook does not rely on current notebook or system state!\n",
    "  * Use `Kernel --> Restart & Run All` to see if you are using any definitions, variables etc. that \n",
    "    are not in scope anymore.\n",
    "  * Do not rename any of the datasets you use, and load it from the same directory that your ipynb-notebook is located in, i.e., your working directory. In particular, when loading your file, make sure that it has the form `nx.read_edgelist(\"example.edgelist\")` instead of `nx.read_edgelist(\"C:/User/Path/to/your/Homework/example.edgelist\")` so that the code directly works from our machines.\n",
    "* Make sure that your code is executable, any task for which the code does not directly run on our machine will be graded with 0 points. Run your notebook from top to bottom, make sure there is no error!\n",
    "  Minimize usage of global variables. Do not reuse variable names multiple times!\n",
    "* Ensure your code/notebook terminates in reasonable time.\n",
    "* Textual answers must always be backed by code and may not refer to results that are not part of\n",
    "  your submission.\n",
    "\n",
    "\n",
    "**There's a story behind each of these points! Don't expect us to fix your stuff!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List team members, including all student IDs, in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials of all team members (you may add or remove items from the list)\n",
    "team_members = [\n",
    "    {\n",
    "        'first_name': 'Alice',\n",
    "        'last_name': 'Foo',\n",
    "        'student_id': 12345\n",
    "    },\n",
    "    {\n",
    "        'first_name': 'Bob',\n",
    "        'last_name': 'Bar',\n",
    "        'student_id': 54321\n",
    "    },\n",
    "    {\n",
    "        'first_name': 'J',\n",
    "        'last_name': 'Doe',\n",
    "        'student_id': 90000\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general immports may go here!\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hamsterster Network\n",
    "\n",
    "In this home assignment we will conduct some analysis of the Hamsterster Network, next to a number of simulations. This network contains friendships and family links between users of the website hamsterster.com, which was an online social network of hamster owners and is now shut down. \n",
    "The network data has been taken from the KONECT repository, and consists of multiple data files. For simplicity, we will only consider the biggest connected component of the network.\n",
    "\n",
    "__References:__  \n",
    "[1] Jérôme Kunegis. KONECT - The Koblenz Network Collection. In Proc. Int. Web Observatory Workshop, pages 1343-1350, 2013  \n",
    "[2] Hamsterster full network dataset -- KONECT, April 2017. [ http://konect.cc/networks/petster-hamster/ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:  Analyzing the Hamsterster Network (22 pts)\n",
    "\n",
    "\n",
    "#### a) Loading the Network (5 pts)\n",
    "The information of the network is stored in multiple files, where one file contains the edges in the network, and one file contains node attributes. Next to the edges, some of the attributes are also of particular interest for us, namely \n",
    "the hamster's  \n",
    "(1) gender,  \n",
    "(2) species (divided into Hamster and Gerbil),  \n",
    "(3) home country (divided into either USA or others).\n",
    "\n",
    "Read in the Hamsterster Network from the datasets that we have provided. In particular, join the information regarding the edges with the desired information regarding the three node attributes in a graph ``G``. Save the three node attributes in ``G`` using attribute names ``'gender'``, ``'species'`` and ``'home'``. Only use attribute values ``'male'`` and ``'female'`` for the gender, ``'hamster'`` and ``'gerbil'`` for the species and ``'usa'`` and ``'other'`` for the home country (do not use upper case letters in the attribute names and values). \n",
    "\n",
    "After reading in the full network data, delete all nodes from ``G`` which do not belong to its biggest connected component. Do NOT reindex the nodes though! In the end, save the (new) numbers of nodes and edges of ``G`` in ``n_nodes`` and ``n_edges``. Save the attribute values of node 1 in a dictionary ``sample_attr`` with format ``{'gender': 'VALUE1', 'species': 'VALUE2', 'home': 'VALUE3'}`` .\n",
    "\n",
    "_Hint: Note that for the species and home country, you can **not** directly take the values from the data file, you have to preprocess them first. Additionally, make sure to transform upper to lower case letters (also for gender)._\n",
    "\n",
    "**Important: Make sure that you do not modify ``G`` anymore in the following tasks (especially in task 3), i.e. create copies before modifying the graph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ... # at the end of subtask 1a), G should only contain the biggest connected component\n",
    "n_nodes = ...\n",
    "n_edges = ...\n",
    "sample_attr = {'gender': ..., 'species': ..., 'home': ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Basic Network Analysis (3 pts)\n",
    "\n",
    "Conduct a basic network analysis of ``G``, i.e. compute the network's density, the average path length, the diameter and its average clustering coefficient. Store the results in ``density``, ``avg_pl``, ``diameter`` and ``avg_cc``. Plot the degree distribution and save it as **'dd.png'**. Do not remove the lines of your code which create and save your .png file.\n",
    "\n",
    "Does the network display the properties that you would typically expect from a social network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = ...\n",
    "avg_pl = ...\n",
    "diameter = ...\n",
    "avg_cc = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1b):** _Please provide your answer regarding your observations here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Analyzing Assortativity (3 pts)\n",
    "\n",
    "Compute the network's degree assortativity coefficient and store it in a variable ``dac``. Plot the average degree correlation $k_{nn}(k)$ against $k$ and save the plot as **'adc.png'**! Do not remove the lines of your code which create and save your .png file.\n",
    "\n",
    "Would you say that this network is assortative, disassortative, or rather neutral? Does the result coincide with what is typically observed in social networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dac = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1c):** _Please provide your answer regarding your observations here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Analyzing Homophily (3 pts)\n",
    "\n",
    "We want to compute the network's homophily with respect to the hamster's  \n",
    "(1) gender,  \n",
    "(2) species (divided into Hamster and Gerbil),  \n",
    "(3) home country (divided into either USA or others),  \n",
    "i.e., the attributes that have been read in a).\n",
    "\n",
    "\n",
    "For each of these three attributes:   \n",
    "(i) measure the homophily of the partition according to the attribute by computing the modularity of the partition,  \n",
    "(ii) argue whether the network is homophilic or heterophilic with respect to that attribute.\n",
    "\n",
    "Store the modularity values in ``m_gender``, ``m_species`` and ``m_home``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gender = ...\n",
    "m_species = ...\n",
    "m_home = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1d):** _Please provide your answers here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Minorities in the Hamsterster Network (8 pts)\n",
    "\n",
    "Finally, we want to analyze how minorities and homophily interplay on this network with respect to the three attributes gender, species and home country.\n",
    "\n",
    "To evaluate the effects of homophily on minorities with respect to these three attributes  \n",
    "(i) compute the shares of the hamsters belonging to each category of each of the three given attributes,    \n",
    "(ii) plot the degree distributions of both classes per attribute against each other,  \n",
    "(iii) compute the average node-wise perception biases regarding the size of the minority group for both majority and minority with respect to each of the three attributes.\n",
    "\n",
    "Store the shares of hamsters into dictionaries ``dist_gender``, ``dist_species`` and ``dist_home`` with format given below. Save the degree distributions as **'dd_gender.png'**, **'dd_species.png'** and **'dd_home.png'**. Do not remove the lines of your code which create and save your .png file. Store the perception biases in ``pb_gender``, ``pb_species`` and ``pb_home`` with format given below.\n",
    "\n",
    "Interpret these results in light of the findings presented in the lecture and the last home assignment (HA2 2c and 2e)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may use this function to compute the node-wise perception biases\n",
    "def perception_bias(G: nx.Graph, attr: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    :param G: networkx graph on which we want to compute all biases\n",
    "    :param attr: string specifying the name of the node attribute which stores the information\n",
    "    :            whether a node belongs to the majority or minority group. The value of that attribute should be 0 \n",
    "    :            if the node belongs to the minority, and 1 otherwise\n",
    "    :\n",
    "    :return: dictionary with node IDs as keys and their respective individual perception bias as value\n",
    "    \"\"\"\n",
    "    f_m = 1 - sum(G.nodes[v][attr] for v in G.nodes)/G.number_of_nodes()\n",
    "    bias_dict = dict()\n",
    "    for v in G.nodes:\n",
    "        bias_dict[v] = 1/f_m/G.degree(v)*sum(1-G.nodes[w][attr] for w in G[v])\n",
    "    return bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code should create the same dictionaries, where ... is replaced by the respective float values\n",
    "\n",
    "dist_gender = {'male': ..., 'female': ...}\n",
    "dist_species = {'hamster': ..., 'gerbil': ...}\n",
    "dist_home = {'usa': ..., 'other': ...}\n",
    "\n",
    "pb_gender = {'majority': ..., 'minority': ...}\n",
    "pb_species = {'majority': ..., 'minority': ...}\n",
    "pb_home = {'majority': ..., 'minority': ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1e):** _Please provide your answer regarding your observations here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:  Detecting Communities in Stochastic Block Models (17 pts)\n",
    "\n",
    "In this task you should use functions from `networkx` wherever possible.\n",
    "\n",
    "#### a) Creating  Graphs According to Stochastic Block Models (4 pts)\n",
    "\n",
    "In this task we want to generate two networks ``G1`` and ``G2`` according to the following specifications of stochastic block models:\n",
    "* Both networks should contain 400 nodes, divided into four communities of 100 nodes each. \n",
    "* Within each community, the probability of an edge existing should be .05 for ``G1``, and 0.02 for ``G2``.\n",
    "* Between adjacent communities (1 and 2, 2 and 3, 3 and 4, **AND 1 and 4**) the probability of an edge existing should be 0.001 for ``G1``, and 0.005 for ``G2``.\n",
    "* There should be no other edges.\n",
    "* To obtain reproducible results, you have to **pass a random seed** to the stochastic block model generator function from `networkx`. Pass `seed = 2021`, as initialised in the cell below!\n",
    "* Each node should have an attribute ``'community'`` which indicates the community (`int(1)` - `int(4)`) that it belongs to.\n",
    "* In the end, you should remove all nodes which are not in the biggest connected component of the resulting graphs.\n",
    "\n",
    "Create two 4x4 matrices ``probs_G1`` and ``probs_G2`` (use list of lists as provided below), where ``probs_G1[i][j] == probs_G1[j][i]`` should be the probability that an edge exists between individual nodes from community `i` and individual nodes from community `j` in ``G1`` (same for ``probs_G2`` and ``G2``). \n",
    "Afterwards, apply the stochastic block model generator from `networkx` to create ``G1`` and ``G2`` from these matrices, following all the specifications listed above. Again, make sure to use the specified seed, and to filter for the biggest connected component as described above.\n",
    "\n",
    "Plot the resulting graphs using a spring layout and color the nodes according to the community they belong to, i.e. two nodes should have the same color if and only if they belong to the same community. Save the plots as **'G1.png'** and **'G2.png'**. Do not remove the lines of your code which create and save your .png file.\n",
    "\n",
    "_Hint: When initialising ``probs_G1`` and ``probs_G2``, don't forget to also include the probability of an edge existing **within** a community._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "\n",
    "probs_G1 = [[..., ..., ..., ...],\n",
    "            [..., ..., ..., ...],\n",
    "            [..., ..., ..., ...],\n",
    "            [..., ..., ..., ...]]\n",
    "G1 = ...\n",
    "\n",
    "probs_G2 = [[..., ..., ..., ...],\n",
    "            [..., ..., ..., ...],\n",
    "            [..., ..., ..., ...],\n",
    "            [..., ..., ..., ...]]\n",
    "G2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Community Detection (5 pts)\n",
    "\n",
    "Apply greedy modularity community detection and the Girvan-Newman algorithm to predict communities on both graphs ``G1`` and ``G2`` - for Girvan-Newman, use the partition into **four communities** . Plot the graphs with node colors according to their predicted communities, using the same orientation as in a). Save the graphs as **'greedymodularity_G1.png'**, **'greedymodularity_G2.png'**, **'girvannewman_G1.png'** and **'girvannewman_G2.png'**. Do not remove the lines of your code which create and save your .png file.\n",
    "\n",
    "Like in 1d), calculate the modularities of the resulting partitions. For greedy modularity community detection, store the values into variables ``m_gm_G1`` and ``m_gm_G2``, and for Girvan-Newman, store the values into ``m_gn_G1`` and ``m_gn_G2``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gm_G1 = ...\n",
    "m_gm_G2 = ...\n",
    "m_gn_G1 = ...\n",
    "m_gn_G2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Rand Index (5 pts)\n",
    "\n",
    "Implement a function that returns the _Rand index_ of a given partition, using the function signature specified in the cell below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_index(H: nx.Graph, gt_attr: str, pred_part: List) -> float:\n",
    "    \"\"\"\n",
    "    :param H: input networkx graph in which ground truth communities are encoded\n",
    "    :param gt_attr: string specifying the name of the node attribute that indicates which ground truth community each \n",
    "    :               node belongs\n",
    "    :param pred_part: list of lists (or sets) of node IDs, where the sublists/sets correspond to predicted communities, \n",
    "    :                 and thus form a partition of all nodes in a graph \n",
    "    :return: the resulting Rand index as a float value\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Evaluating Partitions (3 pts)\n",
    "\n",
    "Apply your implementation from c) to compute the Rand index of the partitions from both graphs and algorithms computed in b). For greedy modularity community detection store the values into variables ``ri_gm_G1`` and ``ri_gm_G2``, for Girvan-Newman store the values into variables ``ri_gn_G1`` and ``ri_gn_G2``.\n",
    "\n",
    "Does one of the two community detection algorithms work significantly better? Explain your answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_gm_G1 = ...\n",
    "ri_gm_G2 = ...\n",
    "ri_gn_G1 = ...\n",
    "ri_gn_G2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2d):** _Please provide your answer regarding your observations here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Label Propagation (20 pts)\n",
    "\n",
    "In this task, we will implement the Label Propgation algorithm which has been presented in lecture, and apply it on the graphs that we created in the previous task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) The Label Propagation Algorithm (10 pts)\n",
    "\n",
    "Implement the label propagation algorithm, using the signature specified in the cell below.\n",
    "Recall that the algorithm works in the following steps:\n",
    "\n",
    "1. Unless a predefined initial labeling is specified, give a unique label to each node in the network \n",
    "2. Arrange the nodes in the network in a random order \n",
    "3. For each node in the network (in this random order), set its label to a label occurring with the highest frequency among its neighbours - ties may be settled arbitrarily. \n",
    "4. go to 2 as long as there exists a node with a label that does not have the highest frequency among its neighbours.\n",
    "\n",
    "In your implementation, you also must provide an option to specify a custom set of initial labels via a corresponding dictionary which maps node IDs to their labels. In particular, this should also allow to initialize nodes **without a label**, by **not** including specific node IDs as keys in the dictionary. Note that in step 3, if for a specific node none of its neighbors currently have a label, this specific node's label should stay as is.\n",
    "In such a setting, you may assume that the input graph is connected, so that eventually, the predefined input labels will propagate through the full network. Note that since the nodes are updated sequentually rather than synchronously, there cannot be any oscillation of labels, so that the algorithm will converge. \n",
    "\n",
    "You have to return a list of lists of node IDs, in which each of the inner lists corresponds to one of the found communities. Thus, two nodes should end up in the same inner list if and only if they belong to the same community. \n",
    "\n",
    "**Note:** There are ways to implement the algorithm in a deterministic or in a non-determinnistic manner. We allow both kinds of solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation(G: nx.Graph, init_labels: Dict=None) -> List[List]:\n",
    "    \"\"\"\n",
    "    :param G: input networkx graph\n",
    "    :param init_labels: dictionary of initial labels, where node IDs serve as keys, and their initial labels as values. \n",
    "                        If not specified/None, all nodes have to be assigned a unique label at the beginning of the algorithm.\n",
    "    :return: List of lists of node IDs, where each sublist corresponds to one of the found communities.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Label Propagation on Stochastic Block Models (3 pts)\n",
    "\n",
    "Apply your implementation from a) **ten times each** on both graphs `G1`and `G2` from task 2. For each of the corresponding partitions, compute both the resulting modularities as well as the Rand index values. Store the ten resulting modularities and Rand index values for graph `G1` into lists ``ri_lp_list_G1`` and ``m_lp_list_G1``, and the ten resulting modularities and Rand indices for `G2` into lists ``ri_lp_list_G2`` and ``m_lp_list_G2``, respectively. Further, for both graphs, compute the average modularity and Rand index that you have obtained from the ten respective runs, and store the results into the variables `avg_m_lp_G1` and `avg_ri_lp_G1` for `G1`, and into the variables `avg_m_lp_G1` and `avg_ri_lp_G2` for `G2`.\n",
    "\n",
    "**Note:** Do not worry if you have a deterministic implementation which always returns the same partitions. We run the label propagation algorithms multiple times to account for variations in the outcomes of non-deterministic implementations. Further, there are also methods to aggregate different partitions, which however are not in scope of this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lp_list_G1 = ...\n",
    "m_lp_list_G2 = ...\n",
    "avg_m_lp_G1 = ...\n",
    "avg_m_lp_G2 = ...\n",
    "ri_lp_list_G1 = ...\n",
    "ri_lp_list_G2 = ...\n",
    "avg_ri_lp_G1 = ...\n",
    "avg_ri_lp_G2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Label Propagation with Pre-informed Initial Labels (4 pts)\n",
    "\n",
    "For both graphs `G1`and `G2`, determine in each community the node with the highest degree. Store these highest-degree nodes per community for `G1` in a dictionary `init_G1`, and for `G2` in a dictionary `init_G2`. In these dictionaries, the four node IDs should serve as keys, and the corresponding community indices should serve as values.\n",
    "\n",
    "Rerun the experiments from b), but this time pass the respective dictionaries `init_G1` and `init_G2` as corresponding values to the `init_labels` parameter of your implementation from a) when looking for communities in `G1`and `G2`.\n",
    "\n",
    "Again, run your label propagation algorithm **ten times** on each of the both graphs `G1`and `G2`, and compute the corresponding resulting modularities and Rand indices. Store the ten resulting modularities and Rand indices for graph `G1` into lists ``ri_lpi_list_G1`` and ``m_lpi_list_G1``, and the ten resulting modularities and Rand indices for `G2` into lists ``ri_lpi_list_G2`` and ``m_lpi_list_G2``, respectively. Once more, for both graphs, compute the average modularity and Rand index that you have obtained from the ten respective runs, and store the results into the variables `avg_m_lpi_G1` and `avg_ri_lpi_G1` for `G1`, and into the variables `avg_m_lpi_G2` and `avg_ri_lpi_G2` for `G2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_G1 = ...\n",
    "init_G2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lpi_list_G1 = ...\n",
    "m_lpi_list_G2 = ...\n",
    "avg_m_lpi_G1 = ...\n",
    "avg_m_lpi_G2 = ...\n",
    "ri_lpi_list_G1 = ...\n",
    "ri_lpi_list_G2 = ...\n",
    "avg_ri_lpi_G1 = ...\n",
    "avg_ri_lpi_G2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Evaluating the Results (3 pts)\n",
    "\n",
    "Give a summary of the results that you have obtained in tasks b) and c), also in light of the results from task 2. How does label propagation fare compared to Girvan-Newman and greedy modularity maximation? Under which circumstances can pre-informed labels be used effectively? Provide a thorough discussion to these questions! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3d):** _Please provide your discussion here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4:  Generating (Dis)Assortative Networks (25 pts)\n",
    "\n",
    "#### a) The Xalvi-Brunet and Sokolov Algorithm (10 pts)\n",
    "\n",
    "Implement the Xalvi-Brunet and Sokolov algorithm for generating (Dis)Assortative Networks, using the signature specified in the cell below.  \n",
    "Recall that the algorithm takes as input a graph, on which edge pairs are going to be rewired for a fixed number of steps. Each of the rewiring steps should use the following procedure:\n",
    "* two random edges are drawn, and their incident nodes are labeled a, b ,c , and d so that $k_a \\geq k_b \\geq k_c \\geq k_d$.\n",
    "* with a given probability $p$, the edges are rewired to make the network more (dis)assortative, following the procedure in the next step. Otherwise, the edges are rewired at random.\n",
    "* When aiming for an assortative network, we rewire the edges such that $a$ joins $b$ and $c$ joins $d$. Otherwise, we join $a$ with $d$ and $b$ with $c$.\n",
    "* To avoid self-loops and multiedges, we redraw the edges and repeat the current step if the two drawn edges share a node, or if the rewiring would yield an edge that already exists in the network (but has not been drawn for rewiring). Note that in the implementation we impose a limit on how often we try to resample if such a case occurs.\n",
    "\n",
    "**Important: Do not modify the input graph directly (i.e. create a copy before modifying the graph).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def xbs(G: nx.Graph, p: float, assortative: bool=True, n_steps: int=100, n_tries: int=100) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    :param G: input graph to rewire\n",
    "    :param p: probability of rewiring for (dis)assortativity \n",
    "    :param assortative: bool indicating whether we want to rewire for an assortative or disassortative network. \n",
    "    :                   If True, rewire for an assortative network. (default is True)\n",
    "    :param n_steps: number of rewiring steps (default is 100)\n",
    "    :param n_tries: number of times we resample an edge pair if a sampled pair shares a node or its rewiring yields an\n",
    "    :               existing edge -> if we exceed this number at some point, we finish the rewiring early and raise a warning\n",
    "    :               (default is 100 which you may use throughout this whole task)\n",
    "    :\n",
    "    :return: resulting networkx graph\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Rewiring the Hamsterster Network (7 pts)\n",
    "\n",
    "Apply your implementation from a) to create ten rewirings of the Hamsterster network. More precisely, create one assortative and one disassortative rewiring for each of the parameter values $p\\in \\{0.2,0.4,0.6,0.8,1\\}$, with $n_{steps}=10000$ rewiring steps. Store the ten graphs into ``graphs`` using the format which is given below. Make sure that you do **not** modify ``G`` from task 1a). For each of the resulting graphs, compute the assortativity coefficient $r$ and store it into ``r_coef`` using the format which is given below. \n",
    "\n",
    "Compute all degree correlations $k_{nn}(k)$. Create two degree correlation plots, one for the assortative, and one for the disassortative rewirings, in which the correlations for all five values of $p$ are displayed in distinct colors. Save them as **'assortative_rw.png'** and **'disassortative_rw.png'**. Do not remove the lines of your code which create and save your .png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code should create the same dictionary, where ... is replaced by the respective networkx graph\n",
    "graphs = {\n",
    "    'assortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    },\n",
    "    'disassortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    }\n",
    "}\n",
    "\n",
    "# your code should create the same dictionary, where ... is replaced by the respective float\n",
    "r_coef = {\n",
    "    'assortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    },\n",
    "    'disassortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Impact of Assortativity on Path Lengths (3 pts)\n",
    "\n",
    "For each of the graphs created in b), compute the average path length and diameter of the network and store the values into ``avg_pls`` and ``diameters`` using the format below. Compare these values against each other as well as against the values of the original graph. What do you observe?  \n",
    "__Note:__ Depending on the computation power of your machine, this computation may take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code should create the same dictionaries, where ... is replaced by the respective float\n",
    "avg_pls = {\n",
    "    'assortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    },\n",
    "    'disassortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    }\n",
    "}\n",
    "\n",
    "diameters = {\n",
    "    'assortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    },\n",
    "    'disassortative': {\n",
    "        '0.2': ...,\n",
    "        '0.4': ...,\n",
    "        '0.6': ...,\n",
    "        '0.8': ...,\n",
    "        '1.0': ...\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A4c):** _Please provide your answer regarding your observations here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Impact of Assortativity on Robustness (5 pts)\n",
    "\n",
    "Conduct a targeted attack (using the function in the cell below) on the original network as well as the assortative and disassortative rewirings from b) with $p=1$, where in each attack you successively delete 500 nodes (always one at a time), each time the node with the highest degree. Save the graphs that result from your attacks in ``G_attacked``, ``assortative_attacked`` and  ``disassortative_attacked``. Make sure that you do **not** modify ``G`` (task 1a), ``graphs['assortative']['1.0']`` and ``graphs['disassortative']['1.0']`` (both task 3b).\n",
    "\n",
    "For each attacked graph, plot the number of removed nodes against the share of the biggest connected component in the graph. Include the curves of all three graphs in the same plot and store it as **'robustness.png'**. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_attack(G: nx.Graph, n: int) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    :param G: networkx graph whose nodes we want to attack\n",
    "    :param n: number of nodes which should be attacked/deleted\n",
    "    :         (always one at the same time - recalculate degrees before deleting next node)\n",
    "    :\n",
    "    :return: resulting networkx graph after deleting n nodes\n",
    "    \"\"\"\n",
    "    Gc = G.copy()\n",
    "    for _ in range(n):\n",
    "        i = sorted(Gc.degree, key=lambda x: x[1], reverse=True)[0][0]\n",
    "        Gc.remove_node(i)\n",
    "    return Gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_attacked = ...\n",
    "assortative_attacked = ...\n",
    "disassortative_attacked = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A4d):** _Please provide your answer regarding your observations here!_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
